{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install word2vec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import operator\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM, SpatialDropout1D, Dropout, Flatten\n",
    "#from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#устанавливаем seed\n",
    "np.random.seed(42)\n",
    "import pymorphy2\n",
    "import re\n",
    "import datetime\n",
    "import sklearn.feature_extraction.text as fex\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from IPython.core.display import display, HTML, Javascript, DisplayObject, display\n",
    "import lime\n",
    "import sklearn.pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import tomita\n",
    "#from tparser import tomita\n",
    "from tomita_parser import text_parse\n",
    "import pandas as pd\n",
    "def normalize(text):\n",
    "    return ' '.join([morph.parse(str(w))[0].normal_form for w in text.split()])\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\\", \" \").replace(u\"╚\", \" \").replace(u\"╩\", \" \")\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\-\\s\\r\\n\\s{1,}|\\-\\s\\r\\n|\\r\\n', '', text) #deleting newlines and line-breaks\n",
    "    text = re.sub('[.,:;_%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-\\'>><`', ' ', text) #deleting symbols  \n",
    "    text = re.sub('-', ' ', text) #deleting symbols  \n",
    "    #text = ' '.join(word[:] for word in text.split() if len(word)>3)\n",
    "    #text = text.encode(\"utf-8\")\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv('dataset1.csv', delimiter=',', encoding='utf-8', error_bad_lines=False)\n",
    "#df_trainR = pd.read_csv('datasetNormFinal.csv', delimiter=',', encoding='utf-8', error_bad_lines=False)\n",
    "df_trainR = pd.read_csv('datasetNormFinal_v2.csv', delimiter=',', encoding='utf-8', error_bad_lines=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.18.1 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.18.1 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.18.1 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/anaconda3/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.18.1 when using version 0.18.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "textColName = \"TEXT\"\n",
    "negatColName =  \"DRAWBACKS\"\n",
    "positColName = \"BENEFITS\"\n",
    "ratingColName = \"RATING\"\n",
    "catColName = \"CATEGORY_ID\"\n",
    "brandColName = \"BRAND_ID\"\n",
    "catNameColName= \"CATEGORY_NAME\"\n",
    "tovarIdColName = \"PRODUCT\"\n",
    "fTextColName = 'fullText'\n",
    "fTextColNameNorm = 'fullTextNorm'\n",
    "tomitaColName = 'tomitaCol'\n",
    "normPosColName = \"NormPos\"\n",
    "normNegColName = \"NormNeg\"\n",
    "normTextColName = 'NormCpom'\n",
    "prodNameColName = 'NAME'\n",
    "#df_train[prodNameColName]\n",
    "with open('noun_adjf_classifiers.pkl', 'rb') as fid:\n",
    "    f = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=df_trainR.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#category_data = df_train[df_train[catNameColName].str.contains(\"MARTPHON\")==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "prodIdList = [30025022,30025023,30024754,30026026]\n",
    "\n",
    "testList = df_train[(df_train[tovarIdColName] == prodIdList[0])]\n",
    "print(len(testList))\n",
    "\n",
    "for prId in prodIdList[1:]:\n",
    "    testList = pd.concat([testList,df_train[(df_train[tovarIdColName] == prId)]])\n",
    "print(len(testList))\n",
    "testList.to_csv(\"newProd2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270941\n",
      "270802\n"
     ]
    }
   ],
   "source": [
    "print(len (df_train))\n",
    "for prId in prodIdList:\n",
    "    df_train = df_train[(df_train[tovarIdColName] != prId)] \n",
    "    #                & (df_train[tovarIdColName] != 30025023 )]\n",
    "print(len (df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('newProd2.csv', delimiter=',', encoding='utf-8', error_bad_lines=False)\n",
    "colList = pd.unique(df_test[catNameColName])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "wtw = gensim.models.Word2Vec.load('word2vec_mvideo.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_feature_vector(words, model, num_features):\n",
    "        #function to average all words vectors in a given paragraph\n",
    "        featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "        nwords = 0\n",
    "\n",
    "        #list containing names of words in the vocabulary\n",
    "        index2word_set = set(model.wv.index2word)\n",
    "        #this is moved as input param for performance reasons\n",
    "        for word in words:\n",
    "            if word in index2word_set:\n",
    "                nwords = nwords+1\n",
    "                featureVec = np.add(featureVec, model[word])\n",
    "\n",
    "        if(nwords>0):\n",
    "            featureVec = np.divide(featureVec, nwords)\n",
    "        return featureVec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spatial\n",
      "\u001b[31m  Could not find a version that satisfies the requirement spatial (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for spatial\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607673750059\n"
     ]
    }
   ],
   "source": [
    "#get average vector for sentence 1\n",
    "from scipy import spatial\n",
    "#from  spatial import distance\n",
    "sentence_1 = \"телефон хороший\"\n",
    "sentence_1_avg_vector = avg_feature_vector(sentence_1.split(), model=wtw, num_features=100)\n",
    "\n",
    "#get average vector for sentence 2\n",
    "sentence_2 = \"телефон обязательно покупайте\"\n",
    "sentence_2_avg_vector = avg_feature_vector(sentence_2.split(), model=wtw, num_features=100)\n",
    "\n",
    "sen1_sen2_similarity =  1 - spatial.distance.cosine(sentence_1_avg_vector,sentence_2_avg_vector)\n",
    "print(sen1_sen2_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentSimilar(sent1, sent2):\n",
    "    sentence_1_avg_vector = avg_feature_vector(normalize(sent1).split(), model=wtw, num_features=100)\n",
    "    sentence_2_avg_vector = avg_feature_vector(normalize(sent2).split(), model=wtw, num_features=100)\n",
    "    res= 1 - spatial.distance.cosine(sentence_1_avg_vector,sentence_2_avg_vector)\n",
    "    return res\n",
    "#s1 = \"ИГРЫ ИДУТ БЕЗ ЛАГОВ ПОЛНОСТЬЮ\"\n",
    "#s2 = \"АППАРАТОМ ПОЛНОСТЬЮ ДОВОЛЕН\"\n",
    "#sentSimilar(normalize(s1),normalize(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxFeatures = 10\n",
    "maxWft = 4\n",
    "maxPerSub = 3\n",
    "coefN = float(0.7)\n",
    "coefS = float(0.7)\n",
    "topCount = 15\n",
    "def word_weight(cv, explainer, words):\n",
    "    \"\"\"word - текст (строка)\"\"\"\n",
    "   # words = [str(w) for w in words if w is not None]\n",
    "    #print(\"call\")\n",
    "    words = \" \".join(words.split(\" \"))\n",
    "    #print(\"splitted\")\n",
    "    exp = explainer.explain_instance(words, cv.predict_proba, num_features=100)\n",
    "    return {k:v for k,v in exp.as_list()}\n",
    "        \n",
    "def printForCat(df_train, df_test,cat, fMod):\n",
    "    cv = sklearn.pipeline.make_pipeline(fMod[1], fMod[0])\n",
    "    explainer = LimeTextExplainer(class_names=[0,1])\n",
    " \n",
    "    category_data = df_train[df_train[catNameColName].str.contains(cat)==True].copy()\n",
    "    category_data[fTextColName] = category_data[textColName].astype('str') + \" \"+category_data[positColName].astype('str')\n",
    "    category_data[fTextColName] = category_data[fTextColName]  +\" \"+category_data[negatColName].astype('str')\n",
    "\n",
    "    if (normTextColName in df_train.columns):\n",
    "       # print (\"data already normalized\")\n",
    "        category_data[fTextColNameNorm] = category_data[normTextColName].astype('str') + \" \"+category_data[normNegColName].astype('str')\n",
    "        category_data[fTextColNameNorm] = category_data[fTextColNameNorm]  +\" \"+category_data[normPosColName].astype('str')\n",
    "    else:\n",
    "        print(\"start normalize at\" + str (datetime.datetime.now()))\n",
    "        category_data[fTextColNameNorm] = category_data[fTextColName].apply(clean_text).apply(normalize)\n",
    "        print(\"finishaed  collect normalize at \" + str (datetime.datetime.now().time()))\n",
    "    category_data_test = df_test[df_test[catNameColName].str.contains(cat)==True].copy()\n",
    "    category_data_test[fTextColName] = category_data_test[textColName].astype('str') + \" \"+category_data_test[positColName].astype('str')\n",
    "    category_data_test[fTextColName] = category_data_test[fTextColName]  +\" \"+category_data_test[negatColName].astype('str')\n",
    "    category_data_test[fTextColNameNorm]=category_data_test[fTextColName].apply(clean_text).apply(normalize)\n",
    "    textAndProdGrS_test = category_data_test.groupby(tovarIdColName )[tovarIdColName, fTextColName].agg(lambda x: \" %s \" % ', '.join(x)).reset_index()\n",
    "    textAndProdGrSNorm_test =  category_data_test.groupby(tovarIdColName )[tovarIdColName, fTextColNameNorm].agg(lambda x: \" %s \" % ', '.join(x)).reset_index()\n",
    "    textAndProdGrS = category_data.groupby(tovarIdColName )[tovarIdColName, fTextColName].agg(lambda x: \" %s \" % ', '.join(x)).reset_index()\n",
    "    textAndProdGrSNorm =  category_data.groupby(tovarIdColName )[tovarIdColName, fTextColNameNorm].agg(lambda x: \" %s \" % ', '.join(x)).reset_index()\n",
    "    textAndProdGrSNorm_All = pd.concat([textAndProdGrSNorm,textAndProdGrSNorm_test])\n",
    "    textAndProdGrS_All = pd.concat([textAndProdGrSNorm,textAndProdGrSNorm_test])\n",
    "   # print(\"total category items \" + str(len(textAndProdGrSNorm_All)))\n",
    "    tf_list = np.array(textAndProdGrSNorm_All)\n",
    "   # print(tf_list.shape)\n",
    "    id_tlist = textAndProdGrSNorm_test[tovarIdColName].tolist()\n",
    "\n",
    "    indList = [i for i in range(0,len(tf_list)) if tf_list[i][0] in id_tlist]\n",
    "    textAndProdGrS_test[tomitaColName] = textAndProdGrS_test[:][fTextColName].apply(text_parse)\n",
    "    tfidf = fex.TfidfVectorizer()\n",
    "    #print(\"start tfidf at\" + str (datetime.datetime.now().time()))\n",
    "    tfIdfMatrix = tfidf.fit_transform(tf_list[:,1])\n",
    "    #print(\"end tf Idf at \" + str (datetime.datetime.now().time()))\n",
    "    ftNames = tfidf.get_feature_names()\n",
    "    \n",
    "    densM = tfIdfMatrix.todense()\n",
    "    for ind in indList[:]:\n",
    "        print(\"#\"*50)\n",
    "        display(HTML('<h2>Продукт</h2>'))\n",
    "        f_weigth = word_weight(cv,explainer,tf_list[ind][1])\n",
    "        display(HTML(df_test[df_test[tovarIdColName] == tf_list[ind][0]][prodNameColName].iloc[0]))\n",
    "        col = densM[ind].tolist()[0]\n",
    "        valD = { ftNames[i]:v for i,v in enumerate(col) if v>0  }\n",
    "        sorted_topWords = sorted(valD.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        sorted_topWords = [ s for s in sorted_topWords if len(s[0])>3]\n",
    "        dict_r = { s[0]:s[1] for s in sorted_topWords}\n",
    "        tomitaD = textAndProdGrS_test[textAndProdGrS_test[tovarIdColName] == textAndProdGrS_All.iloc[ind][tovarIdColName]][tomitaColName]\n",
    "        sublist = list([x[::,0] for x in tomitaD.values][0])\n",
    "        set_ret = list()\n",
    "        tomitaPairs = tomitaD.tolist()[0]\n",
    "        #print(\"start word rating rebuild at \" + str (datetime.datetime.now().time()))\n",
    "        setSent = list()\n",
    "        setSentWord = dict()\n",
    "        top10List=list()\n",
    "        for ts in tomitaPairs:\n",
    "            skip=False\n",
    "\n",
    "\n",
    "            ret =0\n",
    "            retBonus = 0\n",
    "            relationRet = 0\n",
    "            tsn = normalize(ts[0])\n",
    "            if tsn in dict_r.keys():\n",
    "                ret+=dict_r[tsn]*float(coefS)\n",
    "            if tsn in f_weigth.keys():\n",
    "                #print(\"noon ok\")\n",
    "                relationRet+=f_weigth[tsn]*float(coefS)\n",
    "                if f_weigth[tsn]<0:\n",
    "                    relationRet+=f_weigth[tsn]*2\n",
    "                retBonus+=abs(1*f_weigth[tsn]*float(coefS))\n",
    "            retList = list()\n",
    "            for tsPr in ts[1].split(\" \"):\n",
    "                tsPrn = normalize(tsPr)\n",
    "                if tsPrn in dict_r.keys():\n",
    "                    retList.append(dict_r[tsPrn])\n",
    "                if tsPrn in f_weigth.keys():\n",
    "                    #print(\"not noon ok\")\n",
    "                    relationRet+=f_weigth[tsPrn]\n",
    "                    retBonus+=abs(1*f_weigth[tsPrn])\n",
    "                    if f_weigth[tsPrn]<0:\n",
    "                        relationRet+=f_weigth[tsPrn]*2\n",
    "\n",
    "            #ret+=retBonus\n",
    "            retList.sort(reverse = True)\n",
    "            coef = coefN\n",
    "            for retN in retList:\n",
    "                ret+=float(retN)*coef\n",
    "                coef*=coef\n",
    "            if len(top10List) < topCount:\n",
    "                top10List.append(ret)\n",
    "                top10List.sort(reverse=True)\n",
    "            else:\n",
    "                if ret <top10List[-1]:\n",
    "                    continue\n",
    "                top10List.append(ret)\n",
    "                top10List.sort(reverse=True)\n",
    "                del top10List[-1]\n",
    "            for sent in setSent:\n",
    "                #print(sent)\n",
    "                #print(ts[1])\n",
    "                #print( sentSimilar(sent,ts[1]))\n",
    "                if sentSimilar(sent,ts[1]) > float(0.8):\n",
    "                    skip=True\n",
    "                    break\n",
    "            if skip:\n",
    "                #print(sent)\n",
    "                #print(ts[1])\n",
    "                #print( sentSimilar(sent,ts[1]))\n",
    "                continue\n",
    "            setSent.append(ts[1])\n",
    "            \n",
    "            set_ret.append([ts[1],ret,ts[0],relationRet])\n",
    "        \n",
    "        #print(\"end word rating rebuild at \" + str (datetime.datetime.now().time()))\n",
    "        sorted_sent = sorted(set_ret, key=operator.itemgetter(1), reverse=True)\n",
    "        #print(sorted_sent)\n",
    "        for ft in sorted_sent:\n",
    "            if  str(ft[2]) in setSentWord.keys():\n",
    "                setSentWord[ft[2]]+=ft[1]\n",
    "            else:\n",
    "                setSentWord[ft[2]]=ft[1]\n",
    "        sorted_w_sent = sorted(setSentWord.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "               \n",
    "        subDict = dict()\n",
    "        curInd = 0\n",
    "        htmlStr = \"\"\"<table border=\"0\"> <tr> <th>Особенности</th>\n",
    "    <th>Важность</th>\n",
    "    <th>Отношение</th>\n",
    "    \n",
    "    </tr> \"\"\"\n",
    "        for feature in sorted_sent:\n",
    "            if  str(feature[2]) in subDict.keys():\n",
    "                subDict[feature[2]]+=1\n",
    "            else:\n",
    "                subDict[feature[2]]=1\n",
    "            if (subDict[feature[2]] < maxPerSub):\n",
    "                featText = list(feature[0].lower())\n",
    "                featText[0] = featText[0].upper()\n",
    "                featText = \"\".join(featText) \n",
    "                featRet = int(float(feature[3])*10000) \n",
    "                relationText = \"Нейтральное\" if  featRet == 0 else (\"Хорошее\" if featRet>0 else \"Плохое\")\n",
    "                #+  featText.Substring(1);\n",
    "                htmlStr +=\" <tr><td> \"\n",
    "                htmlStr += \"  \"+featText+ \" </td><td>\"\n",
    "                htmlStr += \"  \"+str(int(float(feature[1])*100))+ \" </td><td>\"\n",
    "                htmlStr += \"  \"+relationText+ \" </td><tr>\"\n",
    "\n",
    "                #print(\" особенность: \"+str(featText)+ \" важность \"+ \n",
    "                #      str(int(float(feature[1])*100)))\n",
    "                      #+ \"сущ\" + str(feature[2]))\n",
    "                curInd+=1\n",
    "                \n",
    "         \n",
    "            if curInd > maxFeatures:\n",
    "                break\n",
    "        display(HTML(htmlStr))\n",
    "        for we in sorted_w_sent[:maxWft]:\n",
    "            cnt=0\n",
    "            display(HTML('<h4>'+we[0]+'</h2>'))\n",
    "\n",
    "            for ft in sorted_sent:\n",
    "                if ft[2] == we[0]:\n",
    "                    cnt+=1\n",
    "                    featText = list(ft[0].lower())\n",
    "                    featText[0] = featText[0].upper()\n",
    "                    featText = \"\".join(featText)\n",
    "                    featRet = int(float(ft[3])*10000) \n",
    "                    relationText = \"Нейтрально: \" if  featRet == 0 else (\"Хорошо: \" if featRet>0 else \"Плохо: \")\n",
    "                    featText= relationText + featText\n",
    "                    print(featText)\n",
    "                    if cnt > maxPerSub:\n",
    "                        break\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "dfTest = df_train[normTextColName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>SMARTPHONES                               </h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Продукт</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Смартфон Huawei Honor 4C Pro Grey (TIT-L01)                                                                  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"0\"> <tr> <th>Особенности</th>\n",
       "    <th>Важность</th>\n",
       "    <th>Отношение</th>\n",
       "    \n",
       "    </tr>  <tr><td>   Был телефон с емкой батареей </td><td>  38 </td><td>  Нейтральное </td><tr> <tr><td>   Отличное качество для такой стоимости телефона мощная батарея </td><td>  38 </td><td>  Хорошее </td><tr> <tr><td>   Хочет приобрести недорогой аппарат с хорошей камерой и мощным зарядом батареи </td><td>  38 </td><td>  Хорошее </td><tr> <tr><td>   Батарея телефона слабая </td><td>  37 </td><td>  Плохое </td><tr> <tr><td>   Батареями как например этот </td><td>  33 </td><td>  Нейтральное </td><tr> <tr><td>   Еще уже третий день в настройках не могу найти будильник неплохая батарея камера </td><td>  33 </td><td>  Хорошее </td><tr> <tr><td>   Батареи тоже хватает на долго </td><td>  33 </td><td>  Нейтральное </td><tr> <tr><td>   Батарею держит дольше </td><td>  32 </td><td>  Нейтральное </td><tr> <tr><td>   В остальном очень хороший телефон </td><td>  31 </td><td>  Хорошее </td><tr> <tr><td>   Раньше только мечтать приходилось о батарее </td><td>  31 </td><td>  Нейтральное </td><tr> <tr><td>   Батарея держит заряд несколько дней </td><td>  29 </td><td>  Нейтральное </td><tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>БАТАРЕЯ</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Отличное качество для такой стоимости телефона мощная батарея\n",
      "Плохо: Батарея телефона слабая\n",
      "Хорошо: Батарея держит часов 55-60 с включенным интернетом хотя я периодически играю\n",
      "Хорошо: Хорошая батарея\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>ТЕЛЕФОН</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: В остальном очень хороший телефон\n",
      "Нейтрально: Телефон за эти деньги просто\n",
      "Нейтрально: Телефон который у меня был\n",
      "Нейтрально: Ранее был телефон\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>БАТАРЕИ</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Хочет приобрести недорогой аппарат с хорошей камерой и мощным зарядом батареи\n",
      "Нейтрально: Батареи тоже хватает на долго\n",
      "Нейтрально: Выбор пал из за батареи\n",
      "Нейтрально: Осталось 28% батареи\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>КАМЕРА</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Еще уже третий день в настройках не могу найти будильник неплохая батарея камера\n",
      "Хорошо: Камера хорошая\n",
      "Хорошо: Камера и тд все\n",
      "##################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Продукт</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Смартфон Huawei Honor 4C Pro Gold (TIT-L01)                                                                  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"0\"> <tr> <th>Особенности</th>\n",
       "    <th>Важность</th>\n",
       "    <th>Отношение</th>\n",
       "    \n",
       "    </tr>  <tr><td>   Всему прочему в магазине как обычно нет никаких аксессуаров к таким бюджетным телефонам </td><td>  23 </td><td>  Нейтральное </td><tr> <tr><td>   Камеры очень даже не плохие </td><td>  22 </td><td>  Хорошее </td><tr> <tr><td>   Батарея очень долго держится </td><td>  22 </td><td>  Хорошее </td><tr> <tr><td>   Хорошая батарея </td><td>  22 </td><td>  Хорошее </td><tr> <tr><td>   Хорошая камера </td><td>  22 </td><td>  Хорошее </td><tr> <tr><td>   Телефон советую и цена у него приемлемая и сама </td><td>  21 </td><td>  Плохое </td><tr> <tr><td>   Серверам подключаться не хочет </td><td>  21 </td><td>  Плохое </td><tr> <tr><td>   Не было провода для зарядки других телефонов </td><td>  21 </td><td>  Плохое </td><tr> <tr><td>   Телефон пару раз зависал на пустом месте зависал на глухо но это по ходу проблема слабого </td><td>  21 </td><td>  Плохое </td><tr> <tr><td>   Ищут хорошее качество по приемлемой цене </td><td>  19 </td><td>  Хорошее </td><tr> <tr><td>   Активном использовании очень много минусов </td><td>  19 </td><td>  Хорошее </td><tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>ТЕЛЕФОН</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Плохо: Телефон советую и цена у него приемлемая и сама\n",
      "Плохо: Телефон пару раз зависал на пустом месте зависал на глухо но это по ходу проблема слабого\n",
      "Нейтрально: Телефон за свои\n",
      "Хорошо: Телефон мощный\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>БАТАРЕЯ</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Батарея очень долго держится\n",
      "Хорошо: Хорошая батарея\n",
      "Нейтрально: Достаточно емкая батарея\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>КАМЕРА</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Хорошая камера\n",
      "Хорошо: Камера четкая\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>МИНУСОВ</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Активном использовании очень много минусов\n",
      "Нейтрально: Минусов пока не нашла\n",
      "##################################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Продукт</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Смартфон Huawei Honor 5А Gold (LYO-L21)                                                                      "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"0\"> <tr> <th>Особенности</th>\n",
       "    <th>Важность</th>\n",
       "    <th>Отношение</th>\n",
       "    \n",
       "    </tr>  <tr><td>   Камера очень очень слабая </td><td>  35 </td><td>  Хорошее </td><tr> <tr><td>   Камера отличная 13 мп и 5 мп.телефоном доволен </td><td>  32 </td><td>  Хорошее </td><tr> <tr><td>   Можно скачать камеру </td><td>  31 </td><td>  Хорошее </td><tr> <tr><td>   Камера плохая и видео плохого качества </td><td>  28 </td><td>  Плохое </td><tr> <tr><td>   Камеры не советую </td><td>  28 </td><td>  Хорошее </td><tr> <tr><td>   Камеры нормальные </td><td>  28 </td><td>  Хорошее </td><tr> <tr><td>   Фото или видео для себя тогда лучше </td><td>  28 </td><td>  Хорошее </td><tr> <tr><td>   Фото-видео камера средняя если привыкнуть к автофокусу то оновная камера в дневное время делает хорошие снимки и видео </td><td>  26 </td><td>  Хорошее </td><tr> <tr><td>   Телефон хороший </td><td>  25 </td><td>  Хорошее </td><tr> <tr><td>   Темное время на близком растоянии можно получить не плохое фото </td><td>  24 </td><td>  Плохое </td><tr> <tr><td>   Отличная камера с вспышкой делает потрясающие фотографии </td><td>  24 </td><td>  Хорошее </td><tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>КАМЕРА</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Камера очень очень слабая\n",
      "Хорошо: Камера отличная 13 мп и 5 мп.телефоном доволен\n",
      "Хорошо: Лишних программы и отстойная камера\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>ФОТО</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Фото или видео для себя тогда лучше\n",
      "Плохо: Темное время на близком растоянии можно получить не плохое фото\n",
      "Плохо: Фото расплывчитые не чёткие\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>ТЕЛЕФОН</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хорошо: Телефон хороший\n",
      "Плохо: Пожалела что купила этот телефон\n",
      "Плохо: Телефон прекрасный\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>ВИДЕО</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нейтрально: Видео вообще молчу\n",
      "Хорошо: Любят смотреть и делать прекрасные фотографии и видео\n",
      "Хорошо: Видео достойное\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cat = colList[0][1:]\n",
    "#print(colList)\n",
    "for cat in colList[:1]:\n",
    "    fMod = f['phone']\n",
    "    #print(fMod[1])\n",
    "    display(HTML('<h1>'+str(cat) +'</h1>'))\n",
    "    printForCat(df_train, df_test,cat[1:],fMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#listN = dfTest.tolist()\n",
    "import gensim\n",
    "import pandas as pd\n",
    "entries = [[str(w) for w in e.split()] for e in df.NormCpom]\n",
    "wtw = gensim.models.Word2Vec(entries, size=100, window=5, min_count=5, workers=4)\n",
    "wtw.save('word2vec_mvideo.model')\n",
    "#print(wtw.wv.most_similar(positive=['хороший'], negative=['плохой']))\n",
    "#print(wtw.similarity('отличный', 'ужасный'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strOut = (\"\"\"\n",
    "<html>\n",
    "  <head> </head>\n",
    "  <body>\n",
    "    <div id=\"sample-1\">Клик по ссылке 1</div>\n",
    "    <div id=\"sample-2\" style='display:none;'>Клик по ссылке 2</div>\n",
    "    <div id=\"sample-3\" style='display:none;'>Клик по ссылке 3</div>\n",
    "    \n",
    "    \n",
    "    <ul>\n",
    "      <li onclick=\"view('sample-1')\">17678687</li>\n",
    "      <li onclick=\"view('sample-2')\">29878998789</li>\n",
    "      <li onclick=\"view('sample-3')\">8979777</li>\n",
    "    </ul>\n",
    "    <script>\n",
    " \n",
    "      function view(idDiv){\n",
    "        var divs = document.getElementsByTagName('div');\n",
    "        for(var i = 0; i < divs.length; i++){\n",
    "          if(divs[i].id == idDiv){\n",
    "            divs[i].style.display = 'block';\n",
    "            continue;\n",
    "          }\n",
    "          divs[i].style.display = 'none';\n",
    "        }\n",
    "      }\n",
    " \n",
    " \n",
    "    </script>\n",
    " \n",
    "  </body>\n",
    "</html>\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "display(HTML(strOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "js = \"\"\n",
    "#<script>alert('Hello World!');</script>\"\n",
    "display(HTML(js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = dict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
