{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM, SpatialDropout1D, Dropout, Flatten\n",
    "#from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#устанавливаем seed\n",
    "np.random.seed(42)\n",
    "import pymorphy2\n",
    "import re\n",
    "import datetime\n",
    "import sklearn.feature_extraction.text as fex\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "import tomita\n",
    "#from tparser import tomita\n",
    "from tomita_parser import text_parse\n",
    "import pandas as pd\n",
    "def normalize(text):\n",
    "    return ' '.join([morph.parse(str(w))[0].normal_form for w in text.split()])\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\\", \" \").replace(u\"╚\", \" \").replace(u\"╩\", \" \")\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\-\\s\\r\\n\\s{1,}|\\-\\s\\r\\n|\\r\\n', '', text) #deleting newlines and line-breaks\n",
    "    text = re.sub('[.,:;_%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-\\'>><`', ' ', text) #deleting symbols  \n",
    "    text = re.sub('-', ' ', text) #deleting symbols  \n",
    "    #text = ' '.join(word[:] for word in text.split() if len(word)>3)\n",
    "    #text = text.encode(\"utf-8\")\n",
    "    return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv('dataset1.csv', delimiter=',', encoding='utf-8', error_bad_lines=False)\n",
    "df_train = pd.read_csv('datasetNormFinal.csv', delimiter=',', encoding='utf-8', error_bad_lines=False)\n",
    "\n",
    "df_train = df_train[(df_train[tovarIdColName] != 30025022) & (df_train[tovarIdColName] != 30025023 )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textColName = \"TEXT\"\n",
    "negatColName =  \"DRAWBACKS\"\n",
    "positColName = \"BENEFITS\"\n",
    "ratingColName = \"RATING\"\n",
    "catColName = \"CATEGORY_ID\"\n",
    "brandColName = \"BRAND_ID\"\n",
    "catNameColName= \"CATEGORY_NAME\"\n",
    "tovarIdColName = \"PRODUCT\"\n",
    "fTextColName = 'fullText'\n",
    "fTextColNameNorm = 'fullTextNorm'\n",
    "tomitaColName = 'tomitaCol'\n",
    "normPosColName = \"NormPos\"\n",
    "normNegColName = \"NormNeg\"\n",
    "normTextColName = 'NormCpom'\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('newProd.csv', delimiter=',', encoding='utf-8', error_bad_lines=False)\n",
    "colList = pd.unique(df_test[catNameColName])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxFeatures = 10\n",
    "def printForCat(df_train, df_test,cat):\n",
    "    category_data = df_train[df_train[catNameColName].str.contains(cat)==True]\n",
    "    category_data[fTextColName] = category_data[textColName].astype('str') + \" \"+category_data[positColName].astype('str')\n",
    "    category_data[fTextColName] = category_data[fTextColName]  +\" \"+category_data[negatColName].astype('str')\n",
    "\n",
    "    if (normTextColName in df_train.columns):\n",
    "        print (\"data already normalized\")\n",
    "        category_data[fTextColNameNorm] = category_data[normTextColName].astype('str') + \" \"+category_data[normNegColName].astype('str')\n",
    "        category_data[fTextColNameNorm] = category_data[fTextColNameNorm]  +\" \"+category_data[normPosColName].astype('str')\n",
    "    else:\n",
    "        print(\"start normalize at\" + str (datetime.datetime.now()))\n",
    "        category_data[fTextColNameNorm] = category_data[fTextColName].apply(clean_text).apply(normalize)\n",
    "        print(\"finishaed  collect normalize at \" + str (datetime.datetime.now().time()))\n",
    "    category_data_test = df_test[df_test[catNameColName].str.contains(cat)==True]\n",
    "    category_data_test[fTextColName] = category_data_test[textColName].astype('str') + \" \"+category_data_test[positColName].astype('str')\n",
    "    category_data_test[fTextColName] = category_data_test[fTextColName]  +\" \"+category_data_test[negatColName].astype('str')\n",
    "    category_data_test[fTextColNameNorm]=category_data_test[fTextColName].apply(clean_text).apply(normalize)\n",
    "    textAndProdGrS_test = category_data_test.groupby(tovarIdColName )[tovarIdColName, fTextColName].agg(lambda x: \" %s \" % ', '.join(x)).reset_index()\n",
    "    textAndProdGrSNorm_test =  category_data_test.groupby(tovarIdColName )[tovarIdColName, fTextColNameNorm].agg(lambda x: \" %s \" % ', '.join(x)).reset_index()\n",
    "    textAndProdGrS = category_data.groupby(tovarIdColName )[tovarIdColName, fTextColName].agg(lambda x: \" %s \" % ', '.join(x)).reset_index()\n",
    "    textAndProdGrSNorm =  category_data.groupby(tovarIdColName )[tovarIdColName, fTextColNameNorm].agg(lambda x: \" %s \" % ', '.join(x)).reset_index()\n",
    "    textAndProdGrSNorm_All = pd.concat([textAndProdGrSNorm,textAndProdGrSNorm_test])\n",
    "    textAndProdGrS_All = pd.concat([textAndProdGrSNorm,textAndProdGrSNorm_test])\n",
    "   # print(\"total category items \" + str(len(textAndProdGrSNorm_All)))\n",
    "    tf_list = np.array(textAndProdGrSNorm_All)\n",
    "   # print(tf_list.shape)\n",
    "    id_tlist = textAndProdGrSNorm_test[tovarIdColName].tolist()\n",
    "\n",
    "    indList = [i for i in range(0,len(tf_list)) if tf_list[i][0] in id_tlist]\n",
    "    textAndProdGrS_test[tomitaColName] = textAndProdGrS_test[:][fTextColName].apply(text_parse)\n",
    "    tfidf = fex.TfidfVectorizer()\n",
    "    #print(\"start tfidf at\" + str (datetime.datetime.now().time()))\n",
    "    tfIdfMatrix = tfidf.fit_transform(tf_list[:,1])\n",
    "    #print(\"end tf Idf at \" + str (datetime.datetime.now().time()))\n",
    "    ftNames = tfidf.get_feature_names()\n",
    "    densM = tfIdfMatrix.todense()\n",
    "    for ind in indList[:]:\n",
    "        print(\"#\"*50)\n",
    "        print(\"product ind \" + str(tf_list[ind][0]))\n",
    "        col = densM[ind].tolist()[0]\n",
    "        valD = { ftNames[i]:v for i,v in enumerate(col) if v>0  }\n",
    "        sorted_topWords = sorted(valD.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        sorted_topWords = [ s for s in sorted_topWords if len(s[0])>3]\n",
    "        dict_r = { s[0]:s[1] for s in sorted_topWords}\n",
    "        tomitaD = textAndProdGrS_test[textAndProdGrS_test[tovarIdColName] == textAndProdGrS_All.iloc[ind][tovarIdColName]][tomitaColName]\n",
    "        sublist = list([x[::,0] for x in tomitaD.values][0])\n",
    "        set_ret = dict()\n",
    "        tomitaPairs = tomitaD.tolist()[0]\n",
    "        #print(\"start word rating rebuild at \" + str (datetime.datetime.now().time()))\n",
    "        for ts in tomitaPairs:\n",
    "            ret =0\n",
    "            tsn = normalize(ts[0])\n",
    "            if tsn in dict_r.keys():\n",
    "                ret+=dict_r[tsn]\n",
    "            for tsPr in ts[1].split(\" \"):\n",
    "                tsPrn = normalize(tsPr)\n",
    "                #print(tsPrn)\n",
    "                if tsPrn in dict_r.keys():\n",
    "                 #   print(\"yes\")\n",
    "                    ret+=dict_r[tsPrn]\n",
    "            set_ret[ts[1]]=ret\n",
    "        #print(\"end word rating rebuild at \" + str (datetime.datetime.now().time()))\n",
    "        sorted_sent = sorted(set_ret.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        for feature in sorted_sent[:maxFeatures]:\n",
    "            print(\" особенность: \"+str(feature[0])+ \" важность \"+ str(int(float(feature[1])*100)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARTPHONES                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data already normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "product ind 30025022\n",
      " особенность: ОТЛИЧНОЕ КАЧЕСТВО ДЛЯ ТАКОЙ СТОИМОСТИ ТЕЛЕФОНА МОЩНАЯ БАТАРЕЯ важность 81\n",
      " особенность: БАТАРЕЯ КОТОРАЯ ДЕРЖИТ ЗАРЯД НЕСКОЛЬКО ДНЕЙ И ОЧЕНЬ важность 80\n",
      " особенность: БАТАРЕЯ ДЕРЖАТЬ ЧАСОВ 55-60 С ВКЛЮЧЕННЫМ ИНТЕРНЕТОМ ХОТЯ Я ПЕРИОДИЧЕСКИ ИГРАЮ важность 71\n",
      " особенность: БЫТЬ ТЕЛЕФОН С ЕМКОЙ БАТАРЕЯ важность 69\n",
      " особенность: ХОТЕТЬ ПРИОБРЕСТИ НЕДОРОГОЙ АППАРАТ С ХОРОШЕЙ КАМЕРОЙ И МОЩНЫМ ЗАРЯД БАТАРЕИ важность 69\n",
      " особенность: ЕЩЕ УЖЕ ТРЕТИЙ ДЕНЬ В НАСТРОЙКАХ НЕ МОГУ НАЙТИ БУДИЛЬНИК НЕПЛОХАЯ БАТАРЕЯ КАМЕРА важность 61\n",
      " особенность: БАТАРЕЯ ТЕЛЕФОН СЛАБАЯ важность 60\n",
      " особенность: ЭТОТ ЖЕ ЗАРЯЖАЕТСЯ ЗА 2 ЧАСА И ОЧЕНЬ ХОРОШО ДЕРЖИТ ЗАРЯД ОТ 2-Х ДО 4-Х ДНЕЙ БАТАРЕЙКА И СКОРОСТЬ РАБОТЫ важность 56\n",
      " особенность: БАТАРЕЯ ТОЖЕ ХВАТАЕТ НА ДОЛГО важность 55\n",
      " особенность: БАТАРЕЯ ДЕРЖАТЬ ЗАРЯД НЕСКОЛЬКО важность 55\n",
      "##################################################\n",
      "product ind 30025023\n",
      " особенность: НЕ ТОРМОЗИТ 2 АККУМУЛЯТОР ДОЛГОИГРАЮЩИЙ 3 4G ВЕЗДЕ ЛОВИТ 4 ОТЛИЧНЫЙ ЗВУК 5 ХОРОШАЯ КАМЕРА 6 ANDROID LOLLIPOP 5.1 ПОЗВОЛЯЕТ ПРОСМОТРЕТЬ И ЗАНЯТОСТИ ОЗУ И ЗАКРЫТЬ ЛИШНИЕ ПРИЛОЖЕНИЕ важность 74\n",
      " особенность: ИМЕТЬ БОЛЬШУЮ ЁМКОСТЬ БАТАРЕИ КОТОРОЙ ХВАТАЕТ НА 1,5 ДНЯ ЭТО ЕЩЁ АККУМУЛЯТОР НОРМАЛЬНО НЕ ЗАРЯЖАЛСЯ ПОЛНОСТЬЮ ВЕСЬ ЦИКЛ важность 67\n",
      " особенность: ВЕСЬ ПРОЧЕМУ В МАГАЗИНЕ КАК ОБЫЧНО НЕТ НИКАКИХ АКСЕССУАРОВ К ТАКИМ БЮДЖЕТНЫМ ТЕЛЕФОН важность 53\n",
      " особенность: ТЕЛЕФОН ПАР РАЗ ЗАВИСАЛ НА ПУСТОМ МЕСТЕ ЗАВИСАЛ НА ГЛУХО НО ЭТО ПО ХОДУ ПРОБЛЕМА СЛАБОГО важность 52\n",
      " особенность: ОДИН ОГРОМНЫЙ ПЛЮС ЭТО ЗАРЯДКУ ДЕРЖИТ ОЧЕНЬ ДОЛГО важность 48\n",
      " особенность: ПОЛЬЗОВАТЬСЯ ТРЕТИЙ ДЕНЬ И ПОКА НЕ НАШЛА НИ ОДНОГО МИНУС важность 46\n",
      " особенность: БАТАРЕЯ БЕЗ ПРОБЛЕМ ДЕРЖИТ ДНЯ ДВА АКТИВНОГО важность 42\n",
      " особенность: МОЖНО ДОБАВИТЬ ТОЛЬКО 1 НОМЕР ТЕЛЕФОНА И ФОТО важность 42\n",
      " особенность: КАМЕРА ОЧЕНЬ ДАЖЕ НЕ ПЛОХИЕ важность 41\n",
      " особенность: ПЛАСТИК И ЧЕРЕЗ ПОЛ ГОДА РАБОТЫ ВЫГЛЯДИТ УЖЕ ОЧЕНЬ УСТАВШИМ важность 41\n"
     ]
    }
   ],
   "source": [
    "cat = colList[0][1:]\n",
    "print(cat)\n",
    "printForCat(df_train, df_test,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "densM = tfIdfMatrix.todense()\n",
    "densM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sublist = [x[::, 0] for x in tomitaCol.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slAll=list()\n",
    "for sl in sublist:\n",
    "    type(sl)\n",
    "    slAll.append(list(sl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sublistInd = [i for i,n in enumerate(ftNames)  if n.upper() in slAll  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sublistInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
